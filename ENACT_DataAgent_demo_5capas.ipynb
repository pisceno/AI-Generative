{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfzjm26nGlzsYsuowzLeVP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pisceno/AI-Generative/blob/main/ENACT_DataAgent_demo_5capas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YvtSQSQOzpp",
        "outputId": "3a58267c-f27f-4e24-c9eb-39437a6173fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Monitor] Enviada telemetría: {'node': 'edge-1', 'cpu_pct': 75, 'latency_ms': 15}\n",
            "[Orchestrator] Recibida telemetría de Monitor: {'node': 'edge-1', 'cpu_pct': 75, 'latency_ms': 15}\n",
            "[AI] Forecast: {'placement': 'cloud', 'reason': 'alta carga'}\n",
            "[Orchestrator] Recibida decisión de AI: {'placement': 'cloud', 'reason': 'alta carga'}\n",
            "[DataAgent] Verificando acceso para decisión: {'placement': 'cloud', 'reason': 'alta carga'}\n",
            "[Orchestrator] DataAgent autorizó la decisión: {'placement': 'cloud', 'reason': 'alta carga'}\n",
            "[Dev] Recibida decisión: desplegar en cloud (razón: alta carga)\n",
            "[Monitor] Enviada telemetría: {'node': 'edge-1', 'cpu_pct': 75, 'latency_ms': 15}\n",
            "[Orchestrator] Recibida telemetría de Monitor: {'node': 'edge-1', 'cpu_pct': 75, 'latency_ms': 15}\n",
            "[AI] Forecast: {'placement': 'cloud', 'reason': 'alta carga'}\n",
            "[Orchestrator] Recibida decisión de AI: {'placement': 'cloud', 'reason': 'alta carga'}\n",
            "[DataAgent] Verificando acceso para decisión: {'placement': 'cloud', 'reason': 'alta carga'}\n",
            "[Orchestrator] DataAgent autorizó la decisión: {'placement': 'cloud', 'reason': 'alta carga'}\n",
            "[Dev] Recibida decisión: desplegar en cloud (razón: alta carga)\n",
            "[Monitor] Enviada telemetría: {'node': 'edge-1', 'cpu_pct': 75, 'latency_ms': 15}\n",
            "[Orchestrator] Recibida telemetría de Monitor: {'node': 'edge-1', 'cpu_pct': 75, 'latency_ms': 15}\n",
            "[AI] Forecast: {'placement': 'cloud', 'reason': 'alta carga'}\n",
            "[Orchestrator] Recibida decisión de AI: {'placement': 'cloud', 'reason': 'alta carga'}\n",
            "[DataAgent] Verificando acceso para decisión: {'placement': 'cloud', 'reason': 'alta carga'}\n",
            "[Orchestrator] DataAgent autorizó la decisión: {'placement': 'cloud', 'reason': 'alta carga'}\n",
            "[Dev] Recibida decisión: desplegar en cloud (razón: alta carga)\n",
            "[Monitor] Enviada telemetría: {'node': 'edge-1', 'cpu_pct': 75, 'latency_ms': 15}\n",
            "[Orchestrator] Recibida telemetría de Monitor: {'node': 'edge-1', 'cpu_pct': 75, 'latency_ms': 15}\n",
            "[AI] Forecast: {'placement': 'cloud', 'reason': 'alta carga'}\n",
            "[Orchestrator] Recibida decisión de AI: {'placement': 'cloud', 'reason': 'alta carga'}\n",
            "[DataAgent] Verificando acceso para decisión: {'placement': 'cloud', 'reason': 'alta carga'}\n",
            "[Orchestrator] DataAgent autorizó la decisión: {'placement': 'cloud', 'reason': 'alta carga'}\n",
            "[Dev] Recibida decisión: desplegar en cloud (razón: alta carga)\n",
            ">>> Fin de demo\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "import json\n",
        "\n",
        "# --- Infraestructura simple de mensajes ---\n",
        "class Agent:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.inbox = asyncio.Queue()\n",
        "        self.running = True\n",
        "\n",
        "    async def send(self, other, content):\n",
        "        await other.inbox.put((self.name, content))\n",
        "\n",
        "    async def stop(self):\n",
        "        self.running = False\n",
        "\n",
        "# --- MonitorAgent ---\n",
        "class MonitorAgent(Agent):\n",
        "    async def run(self, orch):\n",
        "        while self.running:\n",
        "            telemetry = {\"node\": \"edge-1\", \"cpu_pct\": 75, \"latency_ms\": 15}\n",
        "            await self.send(orch, {\"type\": \"telemetry\", \"data\": telemetry})\n",
        "            print(f\"[Monitor] Enviada telemetría: {telemetry}\")\n",
        "            await asyncio.sleep(5)\n",
        "\n",
        "# --- OrchestratorAgent ---\n",
        "class OrchestratorAgent(Agent):\n",
        "    async def run(self, ai, dev, data):\n",
        "        while self.running:\n",
        "            sender, msg = await self.inbox.get()\n",
        "            if msg[\"type\"] == \"telemetry\":\n",
        "                telemetry = msg[\"data\"]\n",
        "                print(f\"[Orchestrator] Recibida telemetría de {sender}: {telemetry}\")\n",
        "                await self.send(ai, {\"type\": \"forecast_request\", \"telemetry\": telemetry})\n",
        "            elif msg[\"type\"] == \"forecast_response\":\n",
        "                decision = msg[\"decision\"]\n",
        "                print(f\"[Orchestrator] Recibida decisión de AI: {decision}\")\n",
        "                # Consultar DataAgent antes de enviar a Dev\n",
        "                await self.send(data, {\"type\": \"data_check\", \"decision\": decision})\n",
        "\n",
        "            elif msg[\"type\"] == \"data_authorization\":\n",
        "                authorized_decision = msg[\"decision\"]\n",
        "                print(f\"[Orchestrator] DataAgent autorizó la decisión: {authorized_decision}\")\n",
        "                await self.send(dev, {\"type\": \"deploy_decision\", \"decision\": authorized_decision})\n",
        "\n",
        "# --- AIModelAgent ---\n",
        "class AIModelAgent(Agent):\n",
        "    async def run(self, orch):\n",
        "        while self.running:\n",
        "            sender, msg = await self.inbox.get()\n",
        "            if msg[\"type\"] == \"forecast_request\":\n",
        "                telemetry = msg[\"telemetry\"]\n",
        "                decision = {\"placement\": \"cloud\", \"reason\": \"alta carga\"} if telemetry[\"cpu_pct\"] > 70 else {\"placement\": \"edge\", \"reason\": \"capacidad suficiente\"}\n",
        "                print(f\"[AI] Forecast: {decision}\")\n",
        "                await self.send(orch, {\"type\": \"forecast_response\", \"decision\": decision})\n",
        "\n",
        "# --- DataAgent ---\n",
        "class DataAgent(Agent):\n",
        "    async def run(self, orch):\n",
        "        while self.running:\n",
        "            sender, msg = await self.inbox.get()\n",
        "            if msg[\"type\"] == \"data_check\":\n",
        "                decision = msg[\"decision\"]\n",
        "                # Simular verificación de permisos o disponibilidad de datos\n",
        "                print(f\"[DataAgent] Verificando acceso para decisión: {decision}\")\n",
        "                # En este ejemplo siempre autoriza\n",
        "                await self.send(orch, {\"type\": \"data_authorization\", \"decision\": decision})\n",
        "\n",
        "# --- DevAgent ---\n",
        "class DevAgent(Agent):\n",
        "    async def run(self):\n",
        "        while self.running:\n",
        "            sender, msg = await self.inbox.get()\n",
        "            if msg[\"type\"] == \"deploy_decision\":\n",
        "                decision = msg[\"decision\"]\n",
        "                print(f\"[Dev] Recibida decisión: desplegar en {decision['placement']} (razón: {decision['reason']})\")\n",
        "\n",
        "# --- MAIN ---\n",
        "async def main():\n",
        "    orch = OrchestratorAgent(\"Orchestrator\")\n",
        "    mon = MonitorAgent(\"Monitor\")\n",
        "    ai = AIModelAgent(\"AI\")\n",
        "    data = DataAgent(\"DataAgent\")\n",
        "    dev = DevAgent(\"Dev\")\n",
        "\n",
        "    tasks = [\n",
        "        asyncio.create_task(mon.run(orch)),\n",
        "        asyncio.create_task(orch.run(ai, dev, data)),\n",
        "        asyncio.create_task(ai.run(orch)),\n",
        "        asyncio.create_task(data.run(orch)),\n",
        "        asyncio.create_task(dev.run()),\n",
        "    ]\n",
        "\n",
        "    await asyncio.sleep(20)   # ejecutar 20 segundos\n",
        "    print(\">>> Fin de demo\")\n",
        "    for ag in [orch, mon, ai, data, dev]:\n",
        "        await ag.stop()\n",
        "    for t in tasks:\n",
        "        t.cancel()\n",
        "\n",
        "await main()\n"
      ]
    }
  ]
}